---
---
@article{duan2024pre,
  abbr = {Current Biology},
  bibtex_show={true},
  title={Pre-frontal cortex guides dimension-reducing transformations in the occipito-ventral pathway for categorization behaviors},
  abstract = {To interpret our surroundings, the brain uses a visual categorization process. Current theories and models suggest that this process comprises a hierarchy of different computations that transforms complex, high-dimensional inputs into lower-dimensional representations (i.e., manifolds) in support of multiple categorization behaviors. Here, we tested this hypothesis by analyzing these transformations reflected in dynamic MEG source activity while individual participants actively categorized the same stimuli according to different tasks: face expression, face gender, pedestrian gender, and vehicle type. Results reveal three transformation stages guided by the pre-frontal cortex. At stage 1 (high-dimensional, 50–120 ms), occipital sources represent both task-relevant and task-irrelevant stimulus features; task-relevant features advance into higher ventral/dorsal regions, whereas task-irrelevant features halt at the occipital-temporal junction. At stage 2 (121–150 ms), stimulus feature representations reduce to lower-dimensional manifolds, which then transform into the task-relevant features underlying categorization behavior over stage 3 (161–350 ms). Our findings shed light on how the brain’s network mechanisms transform high-dimensional inputs into specific feature manifolds that support multiple categorization behaviors.},
  author={Duan, Yaocong and Zhan, Jiayu and Gross, Joachim and Ince, Robin AA and Schyns, Philippe G},
  journal={Current Biology},
  volume={34},
  number={15},
  pages={3392--3404},
  year={2024},
  publisher={Elsevier},
  doi={10.1016/j.cub.2024.06.050},
  url={https://www.cell.com/current-biology/fulltext/S0960-9822(24)00834-0},
  pdf={PIIS0960982224008340.pdf},
  code={},
  selected = {}
}

@article{yan2023strength,
  abbr = {Current Biology},
  bibtex_show={true},
  title={Strength of predicted information content in the brain biases decision behavior},
  author={Yan, Yuening and Zhan, Jiayu and Garrod, Oliver and Cui, Xuan and Ince, Robin AA and Schyns, Philippe G},
  abstract = {Prediction-for-perception theories suggest that the brain predicts incoming stimuli to facilitate their categorization. However, it remains unknown what the information contents of these predictions are, which hinders mechanistic explanations. This is because typical approaches cast predictions as an underconstrained contrast between two categories—e.g., faces versus cars, which could lead to predictions of features specific to faces or cars, or features from both categories. Here, to pinpoint the information contents of predictions and thus their mechanistic processing in the brain, we identified the features that enable two different categorical perceptions of the same stimuli. We then trained multivariate classifiers to discern, from dynamic MEG brain responses, the features tied to each perception. With an auditory cueing design, we reveal where, when, and how the brain reactivates visual category features (versus the typical category contrast) before the stimulus is shown. We demonstrate that the predictions of category features have a more direct influence (bias) on subsequent decision behavior in participants than the typical category contrast. Specifically, these predictions are more precisely localized in the brain (lateralized), are more specifically driven by the auditory cues, and their reactivation strength before a stimulus presentation exerts a greater bias on how the individual participant later categorizes this stimulus. By characterizing the specific information contents that the brain predicts and then processes, our findings provide new insights into the brain’s mechanisms of prediction for perception.},
  journal={Current Biology},
  volume={33},
  number={24},
  pages={5505--5514},
  year={2023},
  publisher={Elsevier},
  doi={10.1016/j.cub.2023.10.042},
  url={https://www.cell.com/current-biology/fulltext/S0960-9822(23)01443-4?uuid=uuid%3A389de450-3498-41db-9a71-dc13c37ce9b8},
  pdf={PIIS0960982223014434.pdf},
  code={}
}

@article{zhan2021modeling,
  abbr = {Current Biology},
  bibtex_show={true},
  title={Modeling individual preferences reveals that face beauty is not universally perceived across cultures},
  abstract = {Face attractiveness confers considerable advantages in social interactions, with preferences likely reflecting psychobiological mechanisms shaped by natural selection. Theories of universal beauty propose that attractive faces comprise features that are closer to the population average while optimizing sexual dimorphism (masculine vs. feminine distinction). However, emerging evidence questions this model as an accurate representation of attractive faces, including representing the diversity of beauty preferences across cultures and their individual members. In this study, we used a data-driven method to model, at the individual and cultural levels, the features of attractive female faces, in two matched groups of young male participants (40 East Asians and 40 Western Europeans). We first generated a broad range of same- and other-ethnicity female faces with naturally varying shapes and complexions that participants rated on attractiveness. Then, we reverse correlated the specific features that modulated the perception of face attractiveness in each individual participant. From these individual models, we reconstructed the representation space of face attractiveness. In contrast to theories of universal beauty, we show that attractive face features are distinct from the average (and from sexual dimorphism) in both cultures. We then disentangle attractive face features into those that are shared across cultures, those that are culture-specific, and those that are specific to the individual participant. Our demonstration reveals that face beauty is grounded in diverse features sensitive to culture and ethnicity. Our results have a direct theoretical and methodological impact for representing diversity in theories of social perception and application for the design of culturally and ethnicity sensitive digital agents.},
  author={Zhan, Jiayu and Liu, Meng and Garrod, Oliver GB and Daube, Christoph and Ince, Robin AA and Jack, Rachael E and Schyns, Philippe G},
  journal={Current Biology},
  volume={31},
  number={10},
  pages={2243--2252},
  year={2021},
  publisher={Elsevier},
  doi={10.1016/j.cub.2021.03.013},
  url={https://www.sciencedirect.com/science/article/pii/S0960982221003523},
  pdf={1-s2.0-S0960982221003523-main.pdf},
  code = {},
  selected = {true}
}

@article{zhan2019modelling,
  abbr = {Nature Human Behaviour},
  bibtex_show={true},
  title={Modelling face memory reveals task-generalizable representations},
  author={Zhan, Jiayu and Garrod, Oliver GB and van Rijsbergen, Nicola and Schyns, Philippe G},
  abstract={Current cognitive theories are cast in terms of information-processing mechanisms that use mental representations. For example, people use their mental representations to identify familiar faces under various conditions of pose, illumination and ageing, or to draw resemblance between family members. Yet, the actual information contents of these representations are rarely characterized, which hinders knowledge of the mechanisms that use them. Here, we modelled the three-dimensional representational contents of 4 faces that were familiar to 14 participants as work colleagues. The representational contents were created by reverse-correlating identity information generated on each trial with judgements of the face’s similarity to the individual participant’s memory of this face. In a second study, testing new participants, we demonstrated the validity of the modelled contents using everyday face tasks that generalize identity judgements to new viewpoints, age and sex. Our work highlights that such models of mental representations are critical to understanding generalization behaviour and its underlying information-processing mechanisms.},
  journal={Nature Human Behaviour},
  volume={3},
  number={8},
  pages={817--826},
  year={2019},
  publisher={Nature Publishing Group UK London},
  doi={10.1038/s41562-019-0625-3},
  url={https://www.nature.com/articles/s41562-019-0625-3},
  pdf={s41562-019-0625-3.pdf},
  code={},
  selected = {true}
}

@article{zhan2019dynamic,
  abbr = {Current Biology},
  bibtex_show={true},
  title={Dynamic construction of reduced representations in the brain for perceptual decision behavior},
  abstract = {Over the past decade, extensive studies of the brain regions that support face, object, and scene recognition suggest that these regions have a hierarchically organized architecture that spans the occipital and temporal lobes, where visual categorizations unfold over the first 250 ms of processing. This same architecture is flexibly involved in multiple tasks that require task-specific representations—e.g. categorizing the same object as “a car” or “a Porsche.” While we partly understand where and when these categorizations happen in the occipito-ventral pathway, the next challenge is to unravel how these categorizations happen. That is, how does high-dimensional input collapse in the occipito-ventral pathway to become low dimensional representations that guide behavior? To address this, we investigated what information the brain processes in a visual perception task and visualized the dynamic representation of this information in brain activity. To do so, we developed stimulus information representation (SIR), an information theoretic framework, to tease apart stimulus information that supports behavior from that which does not. We then tracked the dynamic representations of both in magneto-encephalographic (MEG) activity. Using SIR, we demonstrate that a rapid (∼170 ms) reduction of behaviorally irrelevant information occurs in the occipital cortex and that representations of the information that supports distinct behaviors are constructed in the right fusiform gyrus (rFG). Our results thus highlight how SIR can be used to investigate the component processes of the brain by considering interactions between three variables (stimulus information, brain activity, behavior), rather than just two, as is the current norm.},
  author={Zhan, Jiayu and Ince, Robin AA and Van Rijsbergen, Nicola and Schyns, Philippe G},
  journal={Current Biology},
  volume={29},
  number={2},
  pages={319--326},
  year={2019},
  publisher={Elsevier},
  doi = {10.1016/j.cub.2018.11.049},
  url={https://www.cell.com/current-biology/fulltext/S0960-9822(18)31548-3},
  pdf={PIIS0960982218315483.pdf},
  code={},
  selected = {true}
}